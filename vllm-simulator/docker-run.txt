##具体参考https://github.com/llm-d/llm-d-inference-sim
##注意，这个模拟器并不能模拟所有metrics输出，主要是用来构建一个简单的prompt响应模拟环境。
##metrics模拟，请采用llm mock API
docker run --rm --publish 8000:8000 ghcr.io/llm-d/llm-d-inference-sim:dev  --port 8000 --model "Qwen/Qwen2.5-1.5B-Instruct" --lora "tweet-summary-0,tweet-summary-1"